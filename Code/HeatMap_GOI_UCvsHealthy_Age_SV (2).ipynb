{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hTRczVEfQaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bfba296-3fd6-44a0-abc5-cda653e4118e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastcluster in /usr/local/lib/python3.10/dist-packages (1.2.6)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from fastcluster) (1.25.2)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Ongoing list of imports/packages\n",
        "import scipy as sp\n",
        "from pylab import *\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import colormaps\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "import collections\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "from scipy.stats import mannwhitneyu\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from scipy import stats\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster, cophenet\n",
        "from scipy.spatial.distance import pdist\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import shapiro\n",
        "import datetime\n",
        "!pip install fastcluster\n",
        "import fastcluster\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j2T9G8p2FhH"
      },
      "source": [
        "## Data cleaning and reorganization from GEO accession\n",
        "### Work flow and pseudocode is below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oFSfRIwpWHM"
      },
      "source": [
        "Following the GEO accession there are two files. One file we are assuming comes from the manufacturer of the RNA microarray or as a read out has an index, NM ID, common gene abbreviation, full name of gene, GO accession and probe sequences. The second file has indexes and result values by patient. This also includes metadata on the patients.\n",
        "\n",
        "After uploading the .txt files. Metadata was removed and the files were merged so the final dataset has the corresponding NM IDs, index value, gene abb, and patient samples expression values.\n",
        "\n",
        "The next file contains all of the phenotypic data from the samples (there can be multiple samples from a patient)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jliAUWCPzQ26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "05fb237e-48d5-48a8-b686-d039939c8492"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/20440_Project/GSE11223_series_matrix.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-376ca019c53b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/20440_Project/GSE11223_series_matrix.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#converting txt to data frame (removing metadata)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mraw_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#uploading Microarray GeneID data probes and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/20440_Project/GSE11223_series_matrix.txt'"
          ]
        }
      ],
      "source": [
        "\n",
        "#uploading GEO accesion data\n",
        "file_path = '/content/drive/MyDrive/20440_Project/GSE11223_series_matrix.txt'\n",
        "#converting txt to data frame (removing metadata)\n",
        "raw_file = pd.read_csv(file_path, delimiter='\\t', skiprows=50, header=0)\n",
        "\n",
        "#uploading Microarray GeneID data probes and\n",
        "file_path = '/content/drive/MyDrive/20440_Project/GeneID_Probes.txt'\n",
        "#converting txt to data frame\n",
        "ID_raw = pd.read_csv(file_path, delimiter='\\t', header = None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KPpYw_G6Mw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMDFNBQrGs2w"
      },
      "outputs": [],
      "source": [
        "#extracting ID_ref, NM_... ID, and Gene Names\n",
        "ID_abb = ID_raw.iloc[:,[0,3,9]]\n",
        "Column_names = ['ID_REF', 'NM_ID', 'GeneID']\n",
        "ID_abb.columns = Column_names\n",
        "#making sure everything is same dtype before merge\n",
        "ID_abb.loc[:, 'ID_REF']=ID_abb.loc[:, \"ID_REF\"].astype(str)\n",
        "ID_abb.loc[:, 'NM_ID']=ID_abb.loc[:, \"NM_ID\"].astype(str)\n",
        "ID_abb.loc[:, 'GeneID']=ID_abb.loc[:, \"GeneID\"].astype(str)\n",
        "#Replacing GeneID with NM_ID if blank\n",
        "for index, row in ID_abb.iterrows():\n",
        "  if row['GeneID']== 'nan':\n",
        "    ID_abb.at[index, 'GeneID'] = row['NM_ID']\n",
        "\n",
        "#Renaming ID_REF column on raw data\n",
        "column = list(raw_file.columns)\n",
        "raw_file.rename(columns= {column[0]: 'ID_REF'}, inplace = True)\n",
        "#making sure everything is same dtype before merge\n",
        "raw_file.loc[:, 'ID_REF'] = raw_file.loc[:, 'ID_REF'].astype(str)\n",
        "#replacing NaN values with 0\n",
        "raw_file = raw_file.fillna(0)\n",
        "\n",
        "#adding NM_... ID and Gene Names to patient values\n",
        "merged_df = pd.merge(raw_file, ID_abb, on='ID_REF', how ='left')\n",
        "\n",
        "#extracting the name of the columns\n",
        "column_names = list(merged_df.columns)\n",
        "\n",
        "#adding NM_ID, GeneID to front of df\n",
        "new_order = column_names[-2:] + column_names[:-2]\n",
        "merged_df_reorg = merged_df[new_order]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i3bCXSTmuIf"
      },
      "outputs": [],
      "source": [
        "#uploading sample metadata\n",
        "file_path = '/content/drive/MyDrive/20440_Project/GSE11223_newPheno.txt'\n",
        "#converting txt to data frame\n",
        "sample_info = pd.read_csv(file_path, delimiter='\\t')\n",
        "print(sample_info.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0PDa-t-ma1A"
      },
      "source": [
        "## Data manipulation\n",
        "### According to Nobel et al the data has already been normalized and therefore we can go straight into the clustering procedure. We are going to perform heirarchical clustering using a variety of parameters and evaluators.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transposing data so each sample is a row and each gene expression value is a column\n",
        "merged_df_trans = merged_df_reorg.transpose()\n",
        "Sample_type_ex = merged_df_trans.iloc[3:, 89:-1]\n",
        "print(Sample_type_ex.head())"
      ],
      "metadata": {
        "id": "HDvFmJ9xt5Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AV9ZAQMnTArM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDYNkAP1lO_8"
      },
      "outputs": [],
      "source": [
        "#Generating heatmap\n",
        "heatmap = sns.clustermap(Sample_type_ex.apply(pd.to_numeric, errors='coerce'), cmap='viridis', standard_scale=1)\n",
        "plt.title('Heatmap and Clustering of Normalized Expression Data and Sample IDs')\n",
        "heatmap.ax_heatmap.set_xlabel(\"GENE Expression Number\")\n",
        "heatmap.ax_heatmap.set_ylabel(\"Sample ID Number\")\n",
        "\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'heatmap.jpeg', format = 'jpeg' , bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDbviBSwlNJ6"
      },
      "source": [
        "### Determining the accuracy of the clustering with different n-clusters\n",
        "(Normal vs UC n = 2)\n",
        "\n",
        "(Normal vs inflammed n = 2)\n",
        "\n",
        "(Biopsy type n = 4)\n",
        "\n",
        "(Disease and biopsy type n = 14)\n",
        "\n",
        "##Calculating the silhouette coefficient, calinski harabasz score, and the davies bouldin score for each scenerio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOEcAMzBBQq7"
      },
      "outputs": [],
      "source": [
        "Sample_type_ex_numeric = Sample_type_ex.apply(pd.to_numeric, errors='coerce').dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-0dz_hX7B5k"
      },
      "outputs": [],
      "source": [
        "#Clustering by disease + inflammation + location n = 14\n",
        "Sample_type_ex_numeric.columns = Sample_type_ex_numeric.columns.astype(str)\n",
        "kmeansA = KMeans(n_clusters=14)\n",
        "cluster_labelsA = kmeansA.fit_predict(Sample_type_ex_numeric)\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avgA = silhouette_score(Sample_type_ex_numeric, cluster_labelsA)\n",
        "print(\"Silhouette Score (n=14):\", silhouette_avgA)\n",
        "\n",
        "# Calculate Calinski-Harabasz Index\n",
        "calinski_harabasz_score_valueA = calinski_harabasz_score(Sample_type_ex_numeric, cluster_labelsA)\n",
        "print(\"Calinski-Harabasz Index (n=14):\", calinski_harabasz_score_valueA)\n",
        "\n",
        "# Calculate Davies-Bouldin Index\n",
        "davies_bouldin_score_valueA = davies_bouldin_score(Sample_type_ex_numeric, cluster_labelsA)\n",
        "print(\"Davies-Bouldin Index (n=14):\", davies_bouldin_score_valueA)\n",
        "\n",
        "# Add cluster labels to your dataframe\n",
        "Sample_type_ex['Cluster_Labels_DIL'] = cluster_labelsA\n",
        "\n",
        "\n",
        "#Clustering by disease n = 2\n",
        "Sample_type_ex_numeric.columns = Sample_type_ex_numeric.columns.astype(str)\n",
        "kmeansB = KMeans(n_clusters=2)\n",
        "cluster_labelsB = kmeansB.fit_predict(Sample_type_ex_numeric)\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avgB = silhouette_score(Sample_type_ex_numeric, cluster_labelsB)\n",
        "print(\"Silhouette Score (n=2):\", silhouette_avgB)\n",
        "\n",
        "# Calculate Calinski-Harabasz Index\n",
        "calinski_harabasz_score_valueB = calinski_harabasz_score(Sample_type_ex_numeric, cluster_labelsB)\n",
        "print(\"Calinski-Harabasz Index (n=2):\", calinski_harabasz_score_valueB)\n",
        "\n",
        "# Calculate Davies-Bouldin Index\n",
        "davies_bouldin_score_valueB = davies_bouldin_score(Sample_type_ex_numeric, cluster_labelsB)\n",
        "print(\"Davies-Bouldin Index (n=2):\", davies_bouldin_score_valueB)\n",
        "\n",
        "# Add cluster labels to your dataframe\n",
        "Sample_type_ex['Cluster_Labels_D'] = cluster_labelsB\n",
        "\n",
        "\n",
        "#Clustering by location n= 4\n",
        "Sample_type_ex_numeric.columns = Sample_type_ex_numeric.columns.astype(str)\n",
        "kmeansC = KMeans(n_clusters=4)\n",
        "cluster_labelsC = kmeansC.fit_predict(Sample_type_ex_numeric)\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avgC = silhouette_score(Sample_type_ex_numeric, cluster_labelsC)\n",
        "print(\"Silhouette Score (n=4):\", silhouette_avgC)\n",
        "\n",
        "# Calculate Calinski-Harabasz Index\n",
        "calinski_harabasz_score_valueC = calinski_harabasz_score(Sample_type_ex_numeric, cluster_labelsC)\n",
        "print(\"Calinski-Harabasz Index (n=4):\", calinski_harabasz_score_valueC)\n",
        "\n",
        "# Calculate Davies-Bouldin Index\n",
        "davies_bouldin_score_valueC = davies_bouldin_score(Sample_type_ex_numeric, cluster_labelsC)\n",
        "print(\"Davies-Bouldin Index (n=4):\", davies_bouldin_score_valueC)\n",
        "\n",
        "# Add cluster labels to your dataframe\n",
        "Sample_type_ex['Cluster_Labels_L'] = cluster_labelsC\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SViI7E9pYuQ"
      },
      "source": [
        "##Calculating the ARI and accuracy of the clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jvw8pRMTX6i"
      },
      "outputs": [],
      "source": [
        "#Rearranging and cleaning the data for analysis\n",
        "\n",
        "sample_cluster_df = Sample_type_ex.iloc[:, [-3, -2, -1]]\n",
        "\n",
        "# Convert index to a separate column\n",
        "sample_cluster_df['Index_Column'] = sample_cluster_df.index\n",
        "\n",
        "# Split the index column by spaces and expand it into separate columns\n",
        "split_columns = sample_cluster_df['Index_Column'].str.split(expand=True)\n",
        "\n",
        "# Assign the split columns to the DataFrame\n",
        "sample_cluster_df2 = pd.concat([sample_cluster_df, split_columns], axis=1)\n",
        "\n",
        "# Drop the temporary column if needed\n",
        "sample_cluster_df2.drop(columns=['Index_Column'], inplace=True)\n",
        "\n",
        "# Convert the last column to a separate column\n",
        "sample_cluster_df2['Last_Column'] = sample_cluster_df2.iloc[:, -1]\n",
        "\n",
        "# Split the last column by periods and expand it into separate columns\n",
        "split_columns = sample_cluster_df2['Last_Column'].str.split('.', expand=True)\n",
        "\n",
        "# Assign the split columns to the DataFrame\n",
        "sample_cluster_df3 = pd.concat([sample_cluster_df2, split_columns], axis=1)\n",
        "\n",
        "# Drop the temporary column if needed\n",
        "sample_cluster_df3.drop(columns=['Last_Column'], inplace=True)\n",
        "\n",
        "print(sample_cluster_df3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLpt8tmWcMQu"
      },
      "outputs": [],
      "source": [
        "#Setting index to UC or Normal\n",
        "sample_cluster_df4 = sample_cluster_df3.set_index(sample_cluster_df3.columns[3])\n",
        "\n",
        "# Extracting \"Normal\" or \"UC\" from the index and setting it as the first column\n",
        "sample_cluster_df3['Biopsy_Type'] = sample_cluster_df3.index.str[0]\n",
        "\n",
        "# Reordering the columns\n",
        "sample_cluster_df3 = sample_cluster_df3[['Biopsy_Type'] + [col for col in sample_cluster_df3.columns if col != 'Biopsy_Type']]\n",
        "\n",
        "# Resetting the index\n",
        "sample_cluster_df3.reset_index(drop=True, inplace=True)\n",
        "sample_cluster_df4 = sample_cluster_df3.iloc[:, [0,2]]\n",
        "\n",
        "# Replace 'Normal' with 0 and 'UC' with 1 in the 'Biopsy_Type' column\n",
        "sample_cluster_df4['Biopsy_Type'] = sample_cluster_df4['Biopsy_Type'].replace({'N': 0, 'U': 1})\n",
        "\n",
        "# Get the ground truth labels\n",
        "ground_truth_labels = sample_cluster_df4['Biopsy_Type'].values\n",
        "\n",
        "# Assuming 'ground_truth_labels' are the true labels and 'cluster_labelsB' are the labels obtained from clustering\n",
        "ari = adjusted_rand_score(ground_truth_labels, cluster_labelsB)\n",
        "\n",
        "# Print the ARI score\n",
        "print(\"Adjusted Rand Index (ARI):\", ari)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming 'ground_truth_labels' are the true labels and 'cluster_labels' are the labels obtained from clustering\n",
        "accuracy = accuracy_score(ground_truth_labels, cluster_labelsB)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differentially expressed genes between UC and Healthy Patients"
      ],
      "metadata": {
        "id": "MjD0boLeIrDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##WORKS\n",
        "# Determine the differentially expressed genes between healthy and UC\n",
        "merged_df_trans2 = merged_df_trans.iloc[:, 89:-1]\n",
        "merged_df_trans2.index = merged_df_trans2.index.str.split().str[0]\n",
        "\n",
        "# Define the index names for healthy and disease samples\n",
        "Healthy = 'Normal'\n",
        "Disease = 'UC'\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = merged_df_trans2[merged_df_trans2.index == Healthy]\n",
        "UC_rows = merged_df_trans2[merged_df_trans2.index == Disease]\n",
        "\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(columns=merged_df_trans2.columns)\n",
        "fold_change_df = pd.DataFrame(columns = merged_df_trans2.columns )\n",
        "\n",
        "# Calculate average fold change (FC) for each gene\n",
        "for column in merged_df_trans2.columns:\n",
        "    # Convert data to numeric to handle missing values\n",
        "    Healthy_column_numeric = pd.to_numeric(Healthy_rows[column], errors='coerce')\n",
        "    UC_column_numeric = pd.to_numeric(UC_rows[column], errors='coerce')\n",
        "\n",
        "    # Drop missing values\n",
        "    Healthy_column_numeric = Healthy_column_numeric.dropna()\n",
        "    UC_column_numeric = UC_column_numeric.dropna()\n",
        "\n",
        "    # Calculate mean expression in healthy and disease samples\n",
        "    mean_expression_healthy = Healthy_column_numeric.mean()\n",
        "    mean_expression_UC = UC_column_numeric.mean()\n",
        "\n",
        "    # Calculate fold change\n",
        "    fold_change = mean_expression_UC / mean_expression_healthy\n",
        "    fold_change_df[column] = [fold_change]\n",
        "\n",
        "    # Perform t-test if both healthy and disease samples exist\n",
        "    if not (Healthy_column_numeric.empty or UC_column_numeric.empty):\n",
        "        t_stat, p_val = ttest_ind(UC_column_numeric, Healthy_column_numeric)\n",
        "        # Add p-value for each gene to the DataFrame\n",
        "        p_values_df[column] = [p_val]\n",
        "\n",
        "# Set index names for fold change and p-values dataframes\n",
        "fold_change_df.index = ['Fold change']\n",
        "p_values_df.index = ['p-val']\n",
        "\n",
        "# Concatenate the DataFrame containing FC and p-values to the original DataFrame\n",
        "EX_FC_pvals = pd.concat([merged_df_trans2, fold_change_df, p_values_df], ignore_index = False)\n",
        "\n"
      ],
      "metadata": {
        "id": "tPCEVnb7Rsvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#WORKS\n",
        "#Transforming all gene p-vals and FC\n",
        "p_vals = EX_FC_pvals.iloc[-1,:]\n",
        "Fold_changes = EX_FC_pvals.iloc[-2,:]\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "p_vals = pd.to_numeric(p_vals, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log10pval_all = -np.log10(p_vals)\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "Fold_changes = pd.to_numeric(Fold_changes, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log2FC_all = -np.log2(Fold_changes)\n",
        "\n",
        "# Plotting volcano plot\n",
        "\n",
        "VolcanoPlot = plt.scatter(log2FC_all, log10pval_all, alpha = 0.5, color = 'blue', label = 'all' )\n",
        "plt.xlabel(\"log2(Fold Change) [UC/Healthy]\")\n",
        "plt.ylabel(\"-log(p-value)\")\n",
        "plt.title(\"Volcano plot differentially expressed genes between UC and Healthy \")\n",
        "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1)  # Add a horizontal line for significance threshold\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "plt.axvline(-3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'VolcanoPlot_All', format = 'jpeg' , bbox_inches='tight')\n",
        "\n",
        "# Filter only columns with p-values less than 0.05\n",
        "significant_genes = EX_FC_pvals.loc[:, EX_FC_pvals.iloc[-1] < 0.05]\n",
        "\n",
        "# Filter only columns with absolute FC values exceeding 1\n",
        "significant_genes2 = significant_genes.loc[:, (abs(significant_genes.iloc[-2]) > 3)]\n",
        "\n",
        "# Iterate over columns in the DataFrame\n",
        "for column in significant_genes2.columns:\n",
        "    # Check if the absolute FC value is within the desired range\n",
        "    if abs(significant_genes2[column].iloc[-2]) <= 3:\n",
        "        # Drop the column if the condition is not met\n",
        "        significant_genes2.drop(column, axis=1, inplace=True)\n",
        "\n",
        "GOI = significant_genes2.iloc[[1,205,206],:]"
      ],
      "metadata": {
        "id": "DrnfOE9gNCPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOQuT8uYN_PY"
      },
      "outputs": [],
      "source": [
        "GOI2 = GOI.transpose()\n",
        "print(\"Total number of Genes of Interest is\",len(GOI2))\n",
        "GOI2_sort = GOI2.sort_values(by=GOI2.columns[1], ascending = False)\n",
        "#Saving output as .csv to figure folder\n",
        "GOI2_sort.to_csv('/content/drive/MyDrive/20440_Project/Figures/Genes_of_interest.csv', index = False)\n",
        "#Saving output as a .txt to figure folder\n",
        "GOI2_sort.to_csv('/content/drive/MyDrive/20440_Project/Figures/Genes_of_interest.txt', sep='\\t', index = False)\n",
        "print(GOI2_sort.iloc[0:5,:])\n",
        "print(GOI2_sort.iloc[-5:,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SfHjeuXuUA9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performing differential gene expression by biopsy location"
      ],
      "metadata": {
        "id": "S7CO7zH-ABKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the '.number' suffix from the index\n",
        "merged_df_trans = merged_df_reorg.transpose()\n",
        "Sample_type_ex = merged_df_trans.iloc[3:, 89:-1]\n",
        "Sample_type_ex.index = Sample_type_ex.index.str.replace(r'\\.\\d+$', '', regex=True)\n",
        "split = Sample_type_ex.index.str.split()\n",
        "first_word = split.str[0]\n",
        "second_word = split.str[1]\n",
        "third_word = split.str[2]\n",
        "fourth_word = split.str[3]\n",
        "fourth = fourth_word.str.split('.')\n",
        "Sample_type_ex['Condition'] = first_word\n",
        "Sample_type_ex['Biopsy'] = third_word + fourth_word"
      ],
      "metadata": {
        "id": "3CGAp1LW9mZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Sample_type_ex2 = Sample_type_ex.set_index('Condition')\n",
        "# Select all rows where the 'Biopsy' column is 'sigmoidcolon'\n",
        "sigmoid_colon_dataA = Sample_type_ex2[Sample_type_ex2['Biopsy'] == 'sigmoidcolon']\n",
        "descending_colon_dataA = Sample_type_ex2[Sample_type_ex2['Biopsy'] == 'descendingcolon']\n",
        "terminal_ileum_dataA = Sample_type_ex2[Sample_type_ex2['Biopsy'] == 'terminalileum']\n",
        "ascending_colon_dataA = Sample_type_ex2[Sample_type_ex2['Biopsy'] == 'ascendingcolon']"
      ],
      "metadata": {
        "id": "x1lnFANx_HdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sigmoid_colon_dataA))\n",
        "print(len(descending_colon_dataA))\n",
        "print(len(terminal_ileum_dataA))\n",
        "print(len(ascending_colon_dataA))"
      ],
      "metadata": {
        "id": "2ki6WaoPAd9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove the last coulumn\n",
        "sigmoid_colon_data = sigmoid_colon_dataA.iloc[:,:-1]\n",
        "descending_colon_data = descending_colon_dataA.iloc[:,:-1]\n",
        "terminal_ileum_data = terminal_ileum_dataA.iloc[:,:-1]\n",
        "ascending_colon_data = ascending_colon_dataA.iloc[:,:-1]"
      ],
      "metadata": {
        "id": "glUrAJH1B5GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the index names for healthy and disease samples\n",
        "Healthy = 'Normal'\n",
        "Disease = 'UC'\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = sigmoid_colon_data[sigmoid_colon_data.index == Healthy]\n",
        "UC_rows = sigmoid_colon_data[sigmoid_colon_data.index == Disease]\n",
        "\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(columns=sigmoid_colon_data.columns)\n",
        "fold_change_df = pd.DataFrame(columns = sigmoid_colon_data.columns )\n",
        "\n",
        "# Calculate average fold change (FC) for each gene\n",
        "for column in sigmoid_colon_data.columns:\n",
        "    # Convert data to numeric to handle missing values\n",
        "    Healthy_column_numeric = pd.to_numeric(Healthy_rows[column], errors='coerce')\n",
        "    UC_column_numeric = pd.to_numeric(UC_rows[column], errors='coerce')\n",
        "\n",
        "    # Drop missing values\n",
        "    Healthy_column_numeric = Healthy_column_numeric.dropna()\n",
        "    UC_column_numeric = UC_column_numeric.dropna()\n",
        "\n",
        "    # Calculate mean expression in healthy and disease samples\n",
        "    mean_expression_healthy = Healthy_column_numeric.mean()\n",
        "    mean_expression_UC = UC_column_numeric.mean()\n",
        "\n",
        "    # Calculate fold change\n",
        "    fold_change = mean_expression_UC / mean_expression_healthy\n",
        "    fold_change_df[column] = [fold_change]\n",
        "\n",
        "    # Perform t-test if both healthy and disease samples exist\n",
        "    if not (Healthy_column_numeric.empty or UC_column_numeric.empty):\n",
        "        t_stat, p_val = ttest_ind(UC_column_numeric, Healthy_column_numeric)\n",
        "        # Add p-value for each gene to the DataFrame\n",
        "        p_values_df[column] = [p_val]\n",
        "\n",
        "# Set index names for fold change and p-values dataframes\n",
        "fold_change_df.index = ['Fold change']\n",
        "p_values_df.index = ['p-val']\n",
        "\n",
        "# Concatenate the DataFrame containing FC and p-values to the original DataFrame\n",
        "EX_FC_pvals = pd.concat([sigmoid_colon_data, fold_change_df, p_values_df], ignore_index = False)\n",
        "\n",
        "#WORKS\n",
        "#Transforming all gene p-vals and FC\n",
        "p_vals = EX_FC_pvals.iloc[-1,:]\n",
        "Fold_changes = EX_FC_pvals.iloc[-2,:]\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "p_vals = pd.to_numeric(p_vals, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log10pval_all = -np.log10(p_vals)\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "Fold_changes = pd.to_numeric(Fold_changes, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log2FC_all = -np.log2(Fold_changes)\n",
        "\n",
        "# Plotting volcano plot\n",
        "\n",
        "VolcanoPlot = plt.scatter(log2FC_all, log10pval_all, alpha = 0.5, color = 'blue', label = 'all' )\n",
        "plt.xlabel(\"log2(Fold Change) [UC/Healthy]\")\n",
        "plt.ylabel(\"-log(p-value)\")\n",
        "plt.title(\"Volcano plot differentially expressed genes between UC and Healthy in sigmoid colon\")\n",
        "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1)  # Add a horizontal line for significance threshold\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "plt.axvline(-3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'VolcanoPlot_Sigmoid_Colon', format = 'jpeg' , bbox_inches='tight')\n",
        "\n",
        "# Filter only columns with p-values less than 0.05\n",
        "significant_genes = EX_FC_pvals.loc[:, EX_FC_pvals.iloc[-1] < 0.05]\n",
        "\n",
        "# Filter only columns with absolute FC values exceeding 3\n",
        "significant_genes2 = significant_genes.loc[:, (abs(significant_genes.iloc[-2]) > 3)]\n",
        "\n",
        "# Iterate over columns in the DataFrame\n",
        "for column in significant_genes2.columns:\n",
        "    # Check if the absolute FC value is within the desired range\n",
        "    if abs(significant_genes2[column].iloc[-2]) <= 3:\n",
        "        # Drop the column if the condition is not met\n",
        "        significant_genes2.drop(column, axis=1, inplace=True)\n",
        "\n",
        "GOI_sigmoid_colon = significant_genes2\n"
      ],
      "metadata": {
        "id": "Mk0IGrIwBHdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the index names for healthy and disease samples\n",
        "Healthy = 'Normal'\n",
        "Disease = 'UC'\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = descending_colon_data[descending_colon_data.index == Healthy]\n",
        "UC_rows = descending_colon_data[descending_colon_data.index == Disease]\n",
        "\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(columns=descending_colon_data.columns)\n",
        "fold_change_df = pd.DataFrame(columns = descending_colon_data.columns )\n",
        "\n",
        "# Calculate average fold change (FC) for each gene\n",
        "for column in descending_colon_data.columns:\n",
        "    # Convert data to numeric to handle missing values\n",
        "    Healthy_column_numeric = pd.to_numeric(Healthy_rows[column], errors='coerce')\n",
        "    UC_column_numeric = pd.to_numeric(UC_rows[column], errors='coerce')\n",
        "\n",
        "    # Drop missing values\n",
        "    Healthy_column_numeric = Healthy_column_numeric.dropna()\n",
        "    UC_column_numeric = UC_column_numeric.dropna()\n",
        "\n",
        "    # Calculate mean expression in healthy and disease samples\n",
        "    mean_expression_healthy = Healthy_column_numeric.mean()\n",
        "    mean_expression_UC = UC_column_numeric.mean()\n",
        "\n",
        "    # Calculate fold change\n",
        "    fold_change = mean_expression_UC / mean_expression_healthy\n",
        "    fold_change_df[column] = [fold_change]\n",
        "\n",
        "    # Perform t-test if both healthy and disease samples exist\n",
        "    if not (Healthy_column_numeric.empty or UC_column_numeric.empty):\n",
        "        t_stat, p_val = ttest_ind(UC_column_numeric, Healthy_column_numeric)\n",
        "        # Add p-value for each gene to the DataFrame\n",
        "        p_values_df[column] = [p_val]\n",
        "\n",
        "# Set index names for fold change and p-values dataframes\n",
        "fold_change_df.index = ['Fold change']\n",
        "p_values_df.index = ['p-val']\n",
        "\n",
        "# Concatenate the DataFrame containing FC and p-values to the original DataFrame\n",
        "EX_FC_pvals = pd.concat([descending_colon_data, fold_change_df, p_values_df], ignore_index = False)\n",
        "\n",
        "#WORKS\n",
        "#Transforming all gene p-vals and FC\n",
        "p_vals = EX_FC_pvals.iloc[-1,:]\n",
        "Fold_changes = EX_FC_pvals.iloc[-2,:]\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "p_vals = pd.to_numeric(p_vals, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log10pval_all = -np.log10(p_vals)\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "Fold_changes = pd.to_numeric(Fold_changes, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log2FC_all = -np.log2(Fold_changes)\n",
        "\n",
        "# Plotting volcano plot\n",
        "\n",
        "VolcanoPlot = plt.scatter(log2FC_all, log10pval_all, alpha = 0.5, color = 'blue', label = 'all' )\n",
        "plt.xlabel(\"log2(Fold Change) [UC/Healthy]\")\n",
        "plt.ylabel(\"-log(p-value)\")\n",
        "plt.title(\"Volcano plot differentially expressed genes between UC and Healthy in descending colon\")\n",
        "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1)  # Add a horizontal line for significance threshold\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "plt.axvline(-3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'VolcanoPlot_Descending_Colon', format = 'jpeg' , bbox_inches='tight')\n",
        "\n",
        "# Filter only columns with p-values less than 0.05\n",
        "significant_genes = EX_FC_pvals.loc[:, EX_FC_pvals.iloc[-1] < 0.05]\n",
        "\n",
        "# Filter only columns with absolute FC values exceeding 3\n",
        "significant_genes2 = significant_genes.loc[:, (abs(significant_genes.iloc[-2]) > 3)]\n",
        "\n",
        "# Iterate over columns in the DataFrame\n",
        "for column in significant_genes2.columns:\n",
        "    # Check if the absolute FC value is within the desired range\n",
        "    if abs(significant_genes2[column].iloc[-2]) <= 3:\n",
        "        # Drop the column if the condition is not met\n",
        "        significant_genes2.drop(column, axis=1, inplace=True)\n",
        "\n",
        "GOI_descending_colon = significant_genes2\n"
      ],
      "metadata": {
        "id": "EUJHb4PdBxuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the index names for healthy and disease samples\n",
        "Healthy = 'Normal'\n",
        "Disease = 'UC'\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = terminal_ileum_data[terminal_ileum_data.index == Healthy]\n",
        "UC_rows = terminal_ileum_data[terminal_ileum_data.index == Disease]\n",
        "\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(columns=terminal_ileum_data.columns)\n",
        "fold_change_df = pd.DataFrame(columns = terminal_ileum_data.columns )\n",
        "\n",
        "# Calculate average fold change (FC) for each gene\n",
        "for column in terminal_ileum_data.columns:\n",
        "    # Convert data to numeric to handle missing values\n",
        "    Healthy_column_numeric = pd.to_numeric(Healthy_rows[column], errors='coerce')\n",
        "    UC_column_numeric = pd.to_numeric(UC_rows[column], errors='coerce')\n",
        "\n",
        "    # Drop missing values\n",
        "    Healthy_column_numeric = Healthy_column_numeric.dropna()\n",
        "    UC_column_numeric = UC_column_numeric.dropna()\n",
        "\n",
        "    # Calculate mean expression in healthy and disease samples\n",
        "    mean_expression_healthy = Healthy_column_numeric.mean()\n",
        "    mean_expression_UC = UC_column_numeric.mean()\n",
        "\n",
        "    # Calculate fold change\n",
        "    fold_change = mean_expression_UC / mean_expression_healthy\n",
        "    fold_change_df[column] = [fold_change]\n",
        "\n",
        "    # Perform t-test if both healthy and disease samples exist\n",
        "    if not (Healthy_column_numeric.empty or UC_column_numeric.empty):\n",
        "        t_stat, p_val = ttest_ind(UC_column_numeric, Healthy_column_numeric)\n",
        "        # Add p-value for each gene to the DataFrame\n",
        "        p_values_df[column] = [p_val]\n",
        "\n",
        "# Set index names for fold change and p-values dataframes\n",
        "fold_change_df.index = ['Fold change']\n",
        "p_values_df.index = ['p-val']\n",
        "\n",
        "# Concatenate the DataFrame containing FC and p-values to the original DataFrame\n",
        "EX_FC_pvals = pd.concat([terminal_ileum_data, fold_change_df, p_values_df], ignore_index = False)\n",
        "\n",
        "#WORKS\n",
        "#Transforming all gene p-vals and FC\n",
        "p_vals = EX_FC_pvals.iloc[-1,:]\n",
        "Fold_changes = EX_FC_pvals.iloc[-2,:]\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "p_vals = pd.to_numeric(p_vals, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log10pval_all = -np.log10(p_vals)\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "Fold_changes = pd.to_numeric(Fold_changes, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log2FC_all = -np.log2(Fold_changes)\n",
        "\n",
        "# Plotting volcano plot\n",
        "\n",
        "VolcanoPlot = plt.scatter(log2FC_all, log10pval_all, alpha = 0.5, color = 'blue', label = 'all' )\n",
        "plt.xlabel(\"log2(Fold Change) [UC/Healthy]\")\n",
        "plt.ylabel(\"-log(p-value)\")\n",
        "plt.title(\"Volcano plot differentially expressed genes between UC and Healthy in terminal ileum\")\n",
        "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1)  # Add a horizontal line for significance threshold\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "plt.axvline(-3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'VolcanoPlot_Terminal_Ileum', format = 'jpeg' , bbox_inches='tight')\n",
        "\n",
        "# Filter only columns with p-values less than 0.05\n",
        "significant_genes = EX_FC_pvals.loc[:, EX_FC_pvals.iloc[-1] < 0.05]\n",
        "\n",
        "# Filter only columns with absolute FC values exceeding 3\n",
        "significant_genes2 = significant_genes.loc[:, (abs(significant_genes.iloc[-2]) > 3)]\n",
        "\n",
        "# Iterate over columns in the DataFrame\n",
        "for column in significant_genes2.columns:\n",
        "    # Check if the absolute FC value is within the desired range\n",
        "    if abs(significant_genes2[column].iloc[-2]) <= 3:\n",
        "        # Drop the column if the condition is not met\n",
        "        significant_genes2.drop(column, axis=1, inplace=True)\n",
        "\n",
        "GOI_terminal_ileum = significant_genes2\n"
      ],
      "metadata": {
        "id": "wO_Zfp9jBx4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the index names for healthy and disease samples\n",
        "Healthy = 'Normal'\n",
        "Disease = 'UC'\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = ascending_colon_data[ascending_colon_data.index == Healthy]\n",
        "UC_rows = ascending_colon_data[ascending_colon_data.index == Disease]\n",
        "\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(columns=ascending_colon_data.columns)\n",
        "fold_change_df = pd.DataFrame(columns = ascending_colon_data.columns )\n",
        "\n",
        "# Calculate average fold change (FC) for each gene\n",
        "for column in ascending_colon_data.columns:\n",
        "    # Convert data to numeric to handle missing values\n",
        "    Healthy_column_numeric = pd.to_numeric(Healthy_rows[column], errors='coerce')\n",
        "    UC_column_numeric = pd.to_numeric(UC_rows[column], errors='coerce')\n",
        "\n",
        "    # Drop missing values\n",
        "    Healthy_column_numeric = Healthy_column_numeric.dropna()\n",
        "    UC_column_numeric = UC_column_numeric.dropna()\n",
        "\n",
        "    # Calculate mean expression in healthy and disease samples\n",
        "    mean_expression_healthy = Healthy_column_numeric.mean()\n",
        "    mean_expression_UC = UC_column_numeric.mean()\n",
        "\n",
        "    # Calculate fold change\n",
        "    fold_change = mean_expression_UC / mean_expression_healthy\n",
        "    fold_change_df[column] = [fold_change]\n",
        "\n",
        "    # Perform t-test if both healthy and disease samples exist\n",
        "    if not (Healthy_column_numeric.empty or UC_column_numeric.empty):\n",
        "        t_stat, p_val = ttest_ind(UC_column_numeric, Healthy_column_numeric)\n",
        "        # Add p-value for each gene to the DataFrame\n",
        "        p_values_df[column] = [p_val]\n",
        "\n",
        "# Set index names for fold change and p-values dataframes\n",
        "fold_change_df.index = ['Fold change']\n",
        "p_values_df.index = ['p-val']\n",
        "\n",
        "# Concatenate the DataFrame containing FC and p-values to the original DataFrame\n",
        "EX_FC_pvals = pd.concat([ascending_colon_data, fold_change_df, p_values_df], ignore_index = False)\n",
        "\n",
        "#WORKS\n",
        "#Transforming all gene p-vals and FC\n",
        "p_vals = EX_FC_pvals.iloc[-1,:]\n",
        "Fold_changes = EX_FC_pvals.iloc[-2,:]\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "p_vals = pd.to_numeric(p_vals, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log10pval_all = -np.log10(p_vals)\n",
        "\n",
        "# Convert p-values to numeric (in case they are not already)\n",
        "Fold_changes = pd.to_numeric(Fold_changes, errors='coerce')\n",
        "# Take the logarithm of p-values (base 10) for better visualization\n",
        "log2FC_all = -np.log2(Fold_changes)\n",
        "\n",
        "# Plotting volcano plot\n",
        "\n",
        "VolcanoPlot = plt.scatter(log2FC_all, log10pval_all, alpha = 0.5, color = 'blue', label = 'all' )\n",
        "plt.xlabel(\"log2(Fold Change) [UC/Healthy]\")\n",
        "plt.ylabel(\"-log(p-value)\")\n",
        "plt.title(\"Volcano plot differentially expressed genes between UC and Healthy in ascending colon\")\n",
        "plt.axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=1)  # Add a horizontal line for significance threshold\n",
        "plt.axvline(3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "plt.axvline(-3, color='green', linestyle='--', linewidth=1)  # Add a vertical line for fold change threshold\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'VolcanoPlot_Ascending_Colon', format = 'jpeg' , bbox_inches='tight')\n",
        "\n",
        "# Filter only columns with p-values less than 0.05\n",
        "significant_genes = EX_FC_pvals.loc[:, EX_FC_pvals.iloc[-1] < 0.05]\n",
        "\n",
        "# Filter only columns with absolute FC values exceeding 3\n",
        "significant_genes2 = significant_genes.loc[:, (abs(significant_genes.iloc[-2]) > 3)]\n",
        "\n",
        "# Iterate over columns in the DataFrame\n",
        "for column in significant_genes2.columns:\n",
        "    # Check if the absolute FC value is within the desired range\n",
        "    if abs(significant_genes2[column].iloc[-2]) <= 3:\n",
        "        # Drop the column if the condition is not met\n",
        "        significant_genes2.drop(column, axis=1, inplace=True)\n",
        "\n",
        "GOI_ascending_colon = significant_genes2\n"
      ],
      "metadata": {
        "id": "aBYzSAl1ByBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print only the last two rows\n",
        "GOI_sigmoid_colon2 = GOI_sigmoid_colon.transpose()\n",
        "GOI_sigmoid_colon3 = GOI_sigmoid_colon2.iloc[:,[-2,-1]] #gene, FC, p-val\n",
        "\n",
        "GOI_descending_colon2 = GOI_descending_colon.transpose()\n",
        "GOI_descending_colon3 = GOI_descending_colon2.iloc[:,[-2,-1]] #gene, FC, p-val\n",
        "\n",
        "GOI_terminal_ileum2 = GOI_terminal_ileum.transpose()\n",
        "GOI_terminal_ileum3 = GOI_terminal_ileum2.iloc[:,[-2,-1]] #gene, FC, p-val\n",
        "\n",
        "GOI_ascending_colon2 = GOI_ascending_colon.transpose()\n",
        "GOI_ascending_colon3 = GOI_ascending_colon2.iloc[:,[-2,-1]] #gene, FC, p-val\n",
        "\n"
      ],
      "metadata": {
        "id": "ANrP83lNJ0vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IDS = merged_df_trans2.transpose()\n",
        "IDS = IDS.iloc[:, [0,1]]\n",
        "\n",
        "# Adding NM_ID and GeneID to GOI for each\n",
        "GOI_sigmoid_colon_final    = GOI_sigmoid_colon3.merge(   IDS, left_index=True, right_index=True)\n",
        "GOI_descending_colon_final = GOI_descending_colon3.merge(IDS, left_index=True, right_index=True)\n",
        "GOI_terminal_ileum_final   = GOI_terminal_ileum3.merge(  IDS, left_index=True, right_index=True)\n",
        "GOI_ascending_colon_final  = GOI_ascending_colon3.merge( IDS, left_index=True, right_index=True)"
      ],
      "metadata": {
        "id": "Q30JkUXTMAhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extractning GeneIDs from dataframes\n",
        "print(\"sigmoid colon [=] SC\")\n",
        "print(\"descending colon [=] DC\")\n",
        "print(\"terminal ileum [=] TI\")\n",
        "print(\"ascending ileum [=] AC\")\n",
        "GOI_SC_GeneNames = GOI_sigmoid_colon_final.iloc[:, 3]\n",
        "GOI_DC_GeneNames = GOI_descending_colon_final.iloc[:, 3]\n",
        "GOI_TI_GeneNames = GOI_terminal_ileum_final.iloc[:, 3]\n",
        "GOI_AC_GeneNames = GOI_ascending_colon_final.iloc[:, 3]\n",
        "\n",
        "# Assuming df1, df2, df3, and df4 are your DataFrames containing GeneIDs\n",
        "\n",
        "# Extract unique GeneIDs from each DataFrame\n",
        "gene_ids_df1 = set(GOI_SC_GeneNames)\n",
        "gene_ids_df2 = set(GOI_DC_GeneNames)\n",
        "gene_ids_df3 = set(GOI_TI_GeneNames)\n",
        "gene_ids_df4 = set(GOI_AC_GeneNames)\n",
        "\n",
        "# Determine the overlap between the sets of GeneIDs\n",
        "overlap_df1_df2 = gene_ids_df1.intersection(gene_ids_df2)\n",
        "overlap_df1_df3 = gene_ids_df1.intersection(gene_ids_df3)\n",
        "overlap_df1_df4 = gene_ids_df1.intersection(gene_ids_df4)\n",
        "overlap_df2_df3 = gene_ids_df2.intersection(gene_ids_df3)\n",
        "overlap_df2_df4 = gene_ids_df2.intersection(gene_ids_df4)\n",
        "overlap_df3_df4 = gene_ids_df3.intersection(gene_ids_df4)\n",
        "\n",
        "# Print the number of overlapping GeneIDs in each pair of DataFrames\n",
        "print(\"Overlap between SC and DC:\", len(overlap_df1_df2))\n",
        "print(\"Overlap between SC and TI:\", len(overlap_df1_df3))\n",
        "print(\"Overlap between SC and AC:\", len(overlap_df1_df4))\n",
        "print(\"Overlap between DC and TI:\", len(overlap_df2_df3))\n",
        "print(\"Overlap between DC and AC:\", len(overlap_df2_df4))\n",
        "print(\"Overlap between TI and AC:\", len(overlap_df3_df4))\n",
        "\n",
        "# Compute overlaps between all combinations of three sets\n",
        "overlap_1_2_3 = gene_ids_df1.intersection(gene_ids_df2, gene_ids_df3)\n",
        "overlap_1_2_4 = gene_ids_df1.intersection(gene_ids_df2, gene_ids_df4)\n",
        "overlap_1_3_4 = gene_ids_df1.intersection(gene_ids_df3, gene_ids_df4)\n",
        "overlap_2_3_4 = gene_ids_df2.intersection(gene_ids_df3, gene_ids_df4)\n",
        "\n",
        "# Print the sizes of the overlaps\n",
        "print(\"Overlap between DataFrames SC, DC, and TI:\", len(overlap_1_2_3))\n",
        "print(\"Overlap between DataFrames SC, DC, and AC:\", len(overlap_1_2_4))\n",
        "print(\"Overlap between DataFrames SC, TI, and AC:\", len(overlap_1_3_4))\n",
        "print(\"Overlap between DataFrames DC, TI, and AC:\", len(overlap_2_3_4))\n",
        "\n",
        "# Compute the total overlap between all four DataFrames\n",
        "total_overlap = gene_ids_df1.intersection(gene_ids_df2, gene_ids_df3, gene_ids_df4)\n",
        "print(\"Total overlap between all four DataFrames:\", len(total_overlap))"
      ],
      "metadata": {
        "id": "I73sAPkBNUNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Significanlty significantly expressed genes between sigmoid, descending, and ascending colon between UC and Healthy\", overlap_1_2_4)\n",
        "print(\"Significanlty significantly expressed genes between sigmoid colon, descending colon , and terminal ileum\", overlap_1_2_3)"
      ],
      "metadata": {
        "id": "MjSDV_DiXCoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n"
      ],
      "metadata": {
        "id": "1KdoYR7TbFTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(sample_info)\n",
        "# Assuming df is your DataFrame and 'column_name' is the name of the column\n",
        "values_to_find = ['HCLS1', 'CDH24', 'CA314451', 'DCUN1D1', 'POLK', 'BAIAP3']\n",
        "\n",
        "# Filter the DataFrame based on the condition\n",
        "filtered_df = merged_df_reorg[merged_df_reorg['GeneID'].isin(values_to_find)]\n",
        "\n",
        "# Print the rows where the values are found\n",
        "if not filtered_df.empty:\n",
        "    print(\"Rows where the values are found:\")\n",
        "    print(filtered_df)\n",
        "else:\n",
        "    print(\"None of the specified values are found in the column\")\n"
      ],
      "metadata": {
        "id": "8UCmv9W6b48U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = filtered_df.index\n",
        "Info_GOI = merged_df_reorg.iloc[P, :]\n",
        "Info_GOI = Info_GOI.iloc[1:, [1] + list(range(3, len(Info_GOI.columns)))]\n",
        "Info_GOI = Info_GOI.transpose()\n",
        "Info_GOI_trans = Info_GOI.copy()  # Make a copy of the transposed DataFrame\n",
        "Info_GOI_trans.columns = ['POLKa', 'DCUN1D1a', 'CA314451', 'CDH24a', 'CDH24b', 'DCUN1D1b', 'POLKb', 'POLKc', 'DCUN1D1c', 'BAIAP3', 'POLKd']\n",
        "Info_GOI_trans = Info_GOI_trans.iloc[1:,].astype(float)\n",
        "print(Info_GOI_trans.info())\n",
        "\n",
        "#Feature names\n",
        "Feature_names = Info_GOI_trans.columns\n",
        "\n",
        "Info_GOI_trans['Diagnosis'] = Info_GOI_trans.index.str.split().str[0]\n",
        "\n",
        "# Encoding target variable\n",
        "label_encoder = LabelEncoder()\n",
        "Diag_encoded = label_encoder.fit_transform(Info_GOI_trans['Diagnosis'])\n",
        "\n",
        "# Dropping the original diagnosis column\n",
        "Info_GOI_trans = Info_GOI_trans.drop(columns=['Diagnosis'])\n",
        "\n",
        "# Assign features and target variable\n",
        "Features_encoded = pd.get_dummies(Info_GOI_trans)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(Features_encoded, Diag_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the classifier's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming y_true are the true labels and y_pred are the predicted labels\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n"
      ],
      "metadata": {
        "id": "ynnp-mhlCY33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the figure and axis\n",
        "\n",
        "plt.figure(figsize=(20, 20), dpi=300)\n",
        "# Plot the decision tree\n",
        "Tree = plot_tree(rf_classifier.estimators_[0],\n",
        "          feature_names=Features_encoded.columns,\n",
        "          class_names=label_encoder.classes_,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=9,  # Adjust font size\n",
        "          node_ids=True,  # Add node IDs for better reference\n",
        "          proportion=False,  # Adjusts leaf node sizes based on sample proportion\n",
        "          impurity=True,  # Don't display impurity at each node\n",
        "          precision=2)  # Adjust the precision of displayed values\n",
        "\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Decision Tree Visualization\", fontsize=30)\n",
        "plt.xlabel(\"Features\", fontsize=12)\n",
        "plt.ylabel(\"Classes\", fontsize=12)\n",
        "\n",
        "# Remove box around the plot\n",
        "plt.box(False)\n",
        "\n",
        "# Show plot\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'RF_Tree', format = 'jpeg' , bbox_inches='tight')"
      ],
      "metadata": {
        "id": "lQ53kOo9JrPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Continue with POLKb and BAIAP3 for diagnosis since gini score is the highest\n",
        "P = filtered_df.index\n",
        "Info_GOI = merged_df_reorg.iloc[P, :]\n",
        "Info_GOI = Info_GOI.iloc[1:, [1] + list(range(3, len(Info_GOI.columns)))]\n",
        "Info_GOI = Info_GOI.transpose()\n",
        "Info_GOI_trans = Info_GOI.copy()  # Make a copy of the transposed DataFrame\n",
        "Info_GOI_trans.columns = ['POLKa', 'DCUN1D1a', 'CA314451', 'CDH24a', 'CDH24b', 'DCUN1D1b', 'POLKb', 'POLKc', 'DCUN1D1c', 'BAIAP3', 'POLKd']\n",
        "Info_GOI_trans = Info_GOI_trans.drop(columns=['POLKa', 'DCUN1D1a', 'CA314451', 'CDH24a', 'CDH24b', 'DCUN1D1b', 'POLKc', 'DCUN1D1c', 'POLKd'])\n",
        "Info_GOI_trans = Info_GOI_trans.iloc[1:,].astype(float)\n",
        "print(Info_GOI_trans.info())\n",
        "\n",
        "#Feature names\n",
        "Feature_names = Info_GOI_trans.columns\n",
        "\n",
        "Info_GOI_trans['Diagnosis'] = Info_GOI_trans.index.str.split().str[0]\n",
        "\n",
        "# Encoding target variable\n",
        "label_encoder = LabelEncoder()\n",
        "Diag_encoded = label_encoder.fit_transform(Info_GOI_trans['Diagnosis'])\n",
        "\n",
        "# Dropping the original diagnosis column\n",
        "Info_GOI_trans = Info_GOI_trans.drop(columns=['Diagnosis'])\n",
        "\n",
        "# Assign features and target variable\n",
        "Features_encoded = pd.get_dummies(Info_GOI_trans)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(Features_encoded, Diag_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the classifier's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming y_true are the true labels and y_pred are the predicted labels\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "# Initialize the figure and axis\n",
        "\n",
        "plt.figure(figsize=(20, 20), dpi=300)\n",
        "# Plot the decision tree\n",
        "Tree2 = plot_tree(rf_classifier.estimators_[0],\n",
        "          feature_names=Features_encoded.columns,\n",
        "          class_names=label_encoder.classes_,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=8,  # Adjust font size\n",
        "          node_ids=True,  # Add node IDs for better reference\n",
        "          proportion=False,  # Adjusts leaf node sizes based on sample proportion\n",
        "          impurity=True,  # Don't display impurity at each node\n",
        "          precision=2)  # Adjust the precision of displayed values\n",
        "\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Decision Tree Visualization\", fontsize=30)\n",
        "plt.xlabel(\"Features\", fontsize=12)\n",
        "plt.ylabel(\"Classes\", fontsize=12)\n",
        "\n",
        "# Remove box around the plot\n",
        "plt.box(False)\n",
        "\n",
        "# Show plot\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'Tree_2Genes', format = 'jpeg' , bbox_inches='tight')"
      ],
      "metadata": {
        "id": "jCHPSPFuNKXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Determining if there is co-expression of the two genes across all samples UC and Healthy\n",
        "P = filtered_df.index\n",
        "Info_GOI = merged_df_reorg.iloc[P, :]\n",
        "Info_GOI = Info_GOI.iloc[1:, [1] + list(range(3, len(Info_GOI.columns)))]\n",
        "Info_GOI = Info_GOI.transpose()\n",
        "Info_GOI_trans = Info_GOI.copy()  # Make a copy of the transposed DataFrame\n",
        "Info_GOI_trans.columns = ['POLKa', 'DCUN1D1a', 'CA314451', 'CDH24a', 'CDH24b', 'DCUN1D1b', 'POLKb', 'POLKc', 'DCUN1D1c', 'BAIAP3', 'POLKd']\n",
        "Info_GOI_trans = Info_GOI_trans.drop(columns=['POLKa', 'DCUN1D1a', 'CA314451', 'CDH24a', 'CDH24b', 'DCUN1D1b', 'POLKc', 'DCUN1D1c', 'POLKd'])\n",
        "Info_GOI_trans = Info_GOI_trans.iloc[1:,].astype(float)\n",
        "Info_GOI_trans['Diagnosis'] = Info_GOI_trans.index.str.split().str[0]\n",
        "Info_GOI_trans = Info_GOI_trans.set_index('Diagnosis')\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows = Info_GOI_trans[Info_GOI_trans.index == 'Normal']\n",
        "UC_rows = Info_GOI_trans[Info_GOI_trans.index == 'UC']\n",
        "\n",
        "#Healthy\n",
        "POLK_H = Healthy_rows.iloc[:,0]\n",
        "BAIAP3_H = Healthy_rows.iloc[:,1]\n",
        "#UC\n",
        "POLK_UC = UC_rows.iloc[:,0]\n",
        "BAIAP3_UC = UC_rows.iloc[:,1]\n",
        "\n",
        "plt.plot(POLK_H, BAIAP3_H, 'o', color = 'blue', label = 'Healthy')\n",
        "plt.plot(POLK_UC, BAIAP3_UC, 'o', color = 'red', label = 'UC')\n",
        "plt.xlabel('POLK Expression')\n",
        "plt.ylabel('BAIAP3 Expression')\n",
        "plt.legend()\n",
        "plt.title(\"Co-occurance of Differential BAIAP3 and POLK Expression\")\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'POLK_BAIAP3_Expressions', format = 'jpeg' , bbox_inches='tight')"
      ],
      "metadata": {
        "id": "Snkbyv1nPRGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "CVV0wXPQb87e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree for 1-2 Genes and Patient History\n"
      ],
      "metadata": {
        "id": "iYmr7j_EyqQd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-Qx1QKzU2uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_info"
      ],
      "metadata": {
        "id": "9n49eAjI1gd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_info\n",
        "Features_new = ['Birth.Date', 'Gender', 'Ethnicity', 'Diagnosis.Date', 'Family.History', 'Smoking.Status']\n",
        "PT_history = sample_info[Features_new]\n",
        "\n",
        "#Changing birthdate to age\n",
        "PT_history['Birth.Year'] = PT_history['Birth.Date'].str.split('/').str[-1]\n",
        "PT_history['Birth.Year'] = pd.to_numeric(PT_history['Birth.Year']) + 1900\n",
        "PT_history['Age'] = 2008-PT_history['Birth.Year']\n",
        "PT_history.drop(columns = ['Birth.Year', 'Birth.Date'], inplace = True)\n",
        "\n",
        "#Changing diagnosis date to years\n",
        "PT_history['DiagnosisYear'] = PT_history['Diagnosis.Date'].str.split('/').str[-1]\n",
        "PT_history['Time_of_UC'] = 2008-pd.to_numeric(PT_history['DiagnosisYear'])\n",
        "PT_history.drop(columns = ['DiagnosisYear', 'Diagnosis.Date'], inplace = True)\n",
        "\n",
        "# Define smoking status mapping\n",
        "smoking_mapping = {'NaN': 0, 'never': 1, 'current': 2, 'ex': 3, 'unknown': 4}\n",
        "PT_history['Smoking.Status'] = PT_history['Smoking.Status'].map(smoking_mapping)\n",
        "\n",
        "# Convert gender from words (M/F) to numbers\n",
        "gender_mapping = {'M': 0, 'F': 1}\n",
        "PT_history['Gender'] = PT_history['Gender'].map(gender_mapping)\n",
        "\n",
        "# Define ethnicity mapping\n",
        "ethnicity_mapping = {'Caucasian': 0, 'Jewish': 1, 'Asian': 2}\n",
        "PT_history['Ethnicity'] = PT_history['Ethnicity'].map(ethnicity_mapping)\n",
        "\n",
        "#Healthy vs UC\n",
        "# Create a new column 'Disease_Status' based on the values in 'Time_of_UC'\n",
        "PT_history['Disease_Status'] = np.where(PT_history['Time_of_UC'].isna(), 'Healthy', 'UC')\n",
        "PT_history.fillna(0, inplace=True)\n",
        "PT_history.drop(columns = ['Time_of_UC'], inplace = True)\n",
        "print(PT_history.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2_sBLwTUyvPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X = PT_history.drop(columns=['Disease_Status'])\n",
        "y = PT_history['Disease_Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the classifier's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "# Compute sensitivity and specificity\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "# Visualize a decision tree from the random forest (assuming plot_tree function is available)\n",
        "plt.figure(figsize=(20, 20), dpi=300)\n",
        "Tree = plot_tree(rf_classifier.estimators_[0],\n",
        "          feature_names=X.columns,\n",
        "          class_names=rf_classifier.classes_,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=12,\n",
        "          node_ids=True,\n",
        "          proportion=False,\n",
        "          impurity=True,\n",
        "          precision=2)\n",
        "\n",
        "plt.title(\"Decision Tree Visualization\", fontsize=30)\n",
        "plt.xlabel(\"Features\", fontsize=12)\n",
        "plt.ylabel(\"Classes\", fontsize=12)\n",
        "plt.box(False)\n",
        "\n",
        "# Save the plot\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'RF_Tree3', format='jpeg', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "n2wle_aeHlBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading GEO accesion data\n",
        "file_path = '/content/drive/MyDrive/20440_Project/GSE11223_series_matrix.txt'\n",
        "#converting txt to data frame (removing metadata)\n",
        "raw_file2 = pd.read_csv(file_path, delimiter='\\t',skiprows = 139)"
      ],
      "metadata": {
        "id": "tuWbttG9NOlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming ID_REF column on raw data\n",
        "column = list(raw_file2.columns)\n",
        "raw_file2.rename(columns= {column[0]: 'ID_REF'}, inplace = True)\n",
        "#making sure everything is same dtype before merge\n",
        "raw_file2.loc[:, 'ID_REF'] = raw_file2.loc[:, 'ID_REF'].astype(str)\n",
        "#replacing NaN values with 0\n",
        "raw_file2 = raw_file2.fillna(0)\n",
        "\n",
        "#adding NM_... ID and Gene Names to patient values\n",
        "merged_df = pd.merge(raw_file2, ID_abb, on='ID_REF', how ='left')\n",
        "#extracting the name of the columns\n",
        "column_names = list(merged_df.columns)\n",
        "\n",
        "#adding NM_ID, GeneID to front of df\n",
        "new_order = column_names[-2:] + column_names[:-2]\n",
        "merged_df_reorg = merged_df[new_order]\n",
        "merged_df_reorg"
      ],
      "metadata": {
        "id": "i5M8Q0zOXAyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_info"
      ],
      "metadata": {
        "id": "3ADCKL8sYG5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(sample_info)\n",
        "# Assuming df is your DataFrame and 'column_name' is the name of the column\n",
        "values_to_find = ['POLK', 'BAIAP3']\n",
        "\n",
        "# Filter the DataFrame based on the condition\n",
        "filtered_df = merged_df_reorg[merged_df_reorg['GeneID'].isin(values_to_find)]\n",
        "\n",
        "new_columns = [\"POLK\", 'POLK', 'POLK', 'BAIAP3', 'POLK']\n",
        "New_filtered = filtered_df.transpose()\n",
        "New_filtered.columns = new_columns\n",
        "\n",
        "sample_info\n",
        "Features_new2 = ['GSM','Birth.Date', 'Gender', 'Ethnicity', 'Diagnosis.Date', 'Family.History', 'Smoking.Status']\n",
        "PT_history2 = sample_info[Features_new2]\n",
        "\n",
        "#merge GSM column from sample_info and all of PT_history2 on it's index which is GSM values\n",
        "\n",
        "# Merge GSM column from sample_info with PT_history2 on index\n",
        "PT_Final= pd.merge(New_filtered, PT_history2, left_index=True, right_on='GSM')\n",
        "\n",
        "#Changing birthdate to age\n",
        "PT_Final['Birth.Year'] = PT_Final['Birth.Date'].str.split('/').str[-1]\n",
        "PT_Final['Birth.Year'] = pd.to_numeric(PT_Final['Birth.Year']) + 1900\n",
        "PT_Final['Age'] = 2008-PT_Final['Birth.Year']\n",
        "PT_Final.drop(columns = ['Birth.Year', 'Birth.Date', 'GSM'], inplace = True)\n",
        "\n",
        "#Changing diagnosis date to years\n",
        "PT_Final['DiagnosisYear'] = PT_Final['Diagnosis.Date'].str.split('/').str[-1]\n",
        "PT_Final['Time_of_UC'] = 2008-pd.to_numeric(PT_Final['DiagnosisYear'])\n",
        "PT_Final.drop(columns = ['DiagnosisYear', 'Diagnosis.Date'], inplace = True)\n",
        "\n",
        "# Define smoking status mapping\n",
        "smoking_mapping = {'NaN': 0, 'never': 1, 'current': 2, 'ex': 3, 'unknown': 4}\n",
        "PT_Final['Smoking.Status'] = PT_Final['Smoking.Status'].map(smoking_mapping)\n",
        "\n",
        "# Convert gender from words (M/F) to numbers\n",
        "gender_mapping = {'M': 0, 'F': 1}\n",
        "PT_Final['Gender'] = PT_Final['Gender'].map(gender_mapping)\n",
        "\n",
        "# Define ethnicity mapping\n",
        "ethnicity_mapping = {'Caucasian': 0, 'Jewish': 1, 'Asian': 2}\n",
        "PT_Final['Ethnicity'] = PT_Final['Ethnicity'].map(ethnicity_mapping)\n",
        "\n",
        "#Healthy vs UC\n",
        "# Create a new column 'Disease_Status' based on the values in 'Time_of_UC'\n",
        "PT_Final['Disease_Status'] = np.where(PT_Final['Time_of_UC'].isna(), 'Healthy', 'UC')\n",
        "PT_Final.fillna(0, inplace=True)\n",
        "PT_Final.drop(columns = ['Time_of_UC'], inplace = True)\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = PT_Final.drop(columns=['Disease_Status'])\n",
        "y = PT_Final['Disease_Status']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the classifier's performance\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "# Compute sensitivity and specificity\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "# Visualize a decision tree from the random forest (assuming plot_tree function is available)\n",
        "plt.figure(figsize=(20, 20), dpi=300)\n",
        "Tree = plot_tree(rf_classifier.estimators_[0],\n",
        "          feature_names=X.columns,\n",
        "          class_names=rf_classifier.classes_,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=12,\n",
        "          node_ids=True,\n",
        "          proportion=False,\n",
        "          impurity=True,\n",
        "          precision=2)\n",
        "\n",
        "plt.title(\"Decision Tree Visualization\", fontsize=30)\n",
        "plt.xlabel(\"Features\", fontsize=12)\n",
        "plt.ylabel(\"Classes\", fontsize=12)\n",
        "plt.box(False)\n",
        "\n",
        "# Save the plot\n",
        "output_local = '/content/drive/MyDrive/20440_Project/Figures/'\n",
        "plt.savefig(output_local + 'RF_Tree4', format='jpeg', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "gqnlMiQTLZ_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJzFy-1fP4mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzNRZtQf5q9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_ZYozyKOU4_"
      },
      "source": [
        "## Going to perform a differential gene expression analysis by birthyear\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KT_G5tyJVL-5"
      },
      "outputs": [],
      "source": [
        "# looking at age distribution of disease status\n",
        "GSM = sample_info.iloc[:, [0,3,4,7]]\n",
        "\n",
        "# Split the date strings by '/'\n",
        "birth_years = GSM.iloc[:,1].str.split('/')\n",
        "\n",
        "# Select the last element from each split result\n",
        "birth_years = birth_years.str[-1]\n",
        "\n",
        "# Convert birth years to numeric\n",
        "birth_years = pd.to_numeric(birth_years, errors='coerce')\n",
        "# Add birth_years column to GSM DataFrame\n",
        "GSM['birth_years'] = birth_years\n",
        "\n",
        "# Get the current year\n",
        "current_year = datetime.datetime.now().year\n",
        "\n",
        "# Assume a reference point for the century (e.g., 1900 for 'YY' format)\n",
        "century_reference = 1900\n",
        "\n",
        "# Convert birth years to full years\n",
        "GSM['birth_years'] = century_reference + GSM['birth_years']\n",
        "\n",
        "# Calculate age by subtracting birth year from the current year\n",
        "GSM['age'] = current_year - GSM['birth_years']\n",
        "\n",
        "# Selecting rows\n",
        "Healthy_rows_AGE = GSM[GSM.iloc[:,3].isna()]\n",
        "UC_rows_AGE = GSM[~GSM.iloc[:,3].isna()]\n",
        "\n",
        "# Sorting the DataFrame in descending order based on age\n",
        "Healthy_rows_AGE_sorted = Healthy_rows_AGE.sort_values(by=Healthy_rows_AGE.columns[4], ascending=False)\n",
        "UC_rows_AGE_sorted = UC_rows_AGE.sort_values(by=UC_rows_AGE.columns[4], ascending=False)\n",
        "\n",
        "\n",
        "AgeHist = plt.hist(Healthy_rows_AGE_sorted.iloc[3:,4], bins = 4, alpha = 0.5, label = \"Healthy\", edgecolor = 'black')\n",
        "plt.hist(UC_rows_AGE_sorted.iloc[:,4], bins = 4, alpha = 0.5, label = \"UC\",edgecolor = 'black')\n",
        "plt.xlabel(\"Birth Year\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.title(\"Age Distribution by Disease Status\")\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(output_local + 'AgeHist', format = 'jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF7GjHa7W-IG"
      },
      "outputs": [],
      "source": [
        "\n",
        "stat, p = shapiro(Healthy_rows_AGE_sorted.iloc[3:,4])\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('Healthy Samples Not Normally Distributed(fail to reject H0)')\n",
        "else:\n",
        "    print('Healthy Samples Normally Distributed (reject H0)')\n",
        "\n",
        "stat, p = shapiro(UC_rows_AGE_sorted.iloc[:,4])\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print('UC Samples Not Normally Distributed(fail to reject H0)')\n",
        "else:\n",
        "    print('UC Samples Normally Distributed (reject H0)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVUcau3neiva"
      },
      "outputs": [],
      "source": [
        "# Combine age data for healthy and UC groups into a single list\n",
        "data = [Healthy_rows_AGE_sorted.iloc[3:,4], UC_rows_AGE_sorted.iloc[:,4]]\n",
        "\n",
        "# Create a boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "AgeBoxPlot = plt.boxplot(data, labels=['Healthy', 'UC'], patch_artist=True, boxprops=dict(facecolor='lightblue'), medianprops=dict(color='blue'))\n",
        "plt.xlabel('Disease Status')\n",
        "plt.ylabel('Birth Year')\n",
        "plt.title('Age Distribution by Disease Status')\n",
        "plt.grid(True)  # Add gridlines\n",
        "\n",
        "# Perform t-test\n",
        "stat, p = ttest_ind(*data)\n",
        "alpha = 0.05\n",
        "\n",
        "# Add asterisks for significant differences\n",
        "if p < alpha:\n",
        "    plt.text(1.5, max(max(data[0]), max(data[1])) + 1, '*', ha='center', va='bottom', color='Black', fontsize=30)\n",
        "\n",
        "# Extend the y-axis\n",
        "extension_amount = 10  # Adjust this value as needed\n",
        "plt.ylim(min(min(data[0]), min(data[1])) - extension_amount, max(max(data[0]), max(data[1])) + extension_amount)\n",
        "\n",
        "# Show the plot\n",
        "plt.savefig(output_local + 'AgeBoxPlot', format = 'jpeg')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LkjhXbPOR4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vuIb4U7OU5K"
      },
      "outputs": [],
      "source": [
        "# Extract birth years and calculate ages\n",
        "File = raw_file.transpose()\n",
        "\n",
        "birth_years = pd.to_numeric(File.iloc[:, 3].str.split('/').str[-1], errors='coerce')\n",
        "\n",
        "\n",
        "File['birth_years'] = century_reference + birth_years\n",
        "\n",
        "# Calculate ages\n",
        "File['age'] = current_year - File['birth_years']\n",
        "\n",
        "# Bin ages\n",
        "bins = [0, 40, 60, 80, 100]\n",
        "labels = ['0-40', '41-60', '61-80', '81-100']\n",
        "File['age_bin'] = pd.cut(File['age'], bins=bins, labels=labels, right=False)\n",
        "File = File.set_index('age_bin')\n",
        "#Dataframe that has age bin as index and each row is a different column\n",
        "File = File.iloc[1:, 89:-3]\n",
        "# Initialize an empty DataFrame to store p-values\n",
        "p_values_df = pd.DataFrame(index=labels, columns=File.columns)\n",
        "\n",
        "# Perform t-test for each gene expression across each age bin\n",
        "for label in labels:\n",
        "    age_group = File.loc[File.index == label]\n",
        "    for column in File.columns:\n",
        "        # Convert data to numeric to handle missing values\n",
        "        age_group_numeric = pd.to_numeric(age_group[column], errors='coerce')\n",
        "        first_age_group_numeric = pd.to_numeric(File.loc[File.index == labels[0], column], errors='coerce')\n",
        "        # Drop missing values\n",
        "        age_group_numeric = age_group_numeric.dropna()\n",
        "        first_age_group_numeric = first_age_group_numeric.dropna()\n",
        "        # Perform t-test for each age group compared to the first one\n",
        "        if not (age_group_numeric.empty or first_age_group_numeric.empty):\n",
        "            _, p_val = ttest_ind(age_group_numeric, first_age_group_numeric)\n",
        "            p_values_df.at[label, column] = p_val\n",
        "\n",
        "# Bonferroni correction\n",
        "p_values_corrected = p_values_df.apply(lambda x: x * len(p_values_df.columns), axis=1)\n",
        "\n",
        "# Print the DataFrame with corrected p-values\n",
        "print(p_values_corrected.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_KEQf9NOU5K"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import f_oneway\n",
        "# Extract birth years and calculate ages\n",
        "File = raw_file.transpose()\n",
        "\n",
        "birth_years = pd.to_numeric(File.iloc[:, 3].str.split('/').str[-1], errors='coerce')\n",
        "\n",
        "\n",
        "File['birth_years'] = century_reference + birth_years\n",
        "\n",
        "# Calculate ages\n",
        "File['age'] = current_year - File['birth_years']\n",
        "\n",
        "# Bin ages\n",
        "bins = [0, 40, 60, 80, 100]\n",
        "labels = ['0-40', '41-60', '61-80', '81-100']\n",
        "File['age_bin'] = pd.cut(File['age'], bins=bins, labels=labels, right=False)\n",
        "File = File.set_index('age_bin')\n",
        "#Dataframe that has age bin as index and each row is a different column\n",
        "File = File.iloc[1:, 89:-3]\n",
        "# Assuming 'File' contains gene expression data with age groups in columns\n",
        "# Each column represents a different age group\n",
        "\n",
        "# Define the age group columns\n",
        "age_group_columns = ['0-40', '41-60', '61-80', '81-100']\n",
        "\n",
        "# Initialize an empty DataFrame to store ANOVA results\n",
        "anova_results = pd.DataFrame(index=File.columns, columns=['F-statistic', 'p-value'])\n",
        "\n",
        "# Perform ANOVA test for each gene\n",
        "for column in File.columns:\n",
        "    # Extract expression values for each age group\n",
        "    age_group_data = [File[column][File.index == age_group].dropna() for age_group in age_group_columns]\n",
        "\n",
        "    # Perform ANOVA test\n",
        "    f_statistic, p_value = f_oneway(*age_group_data)\n",
        "\n",
        "    # Store results in the DataFrame\n",
        "    anova_results.loc[column, 'F-statistic'] = f_statistic\n",
        "    anova_results.loc[column, 'p-value'] = p_value\n",
        "\n",
        "# Print ANOVA results\n",
        "print(anova_results.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivQ2GjyyOU5L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the '.number' suffix from the index\n",
        "Sample_type_ex.index = Sample_type_ex.index.str.replace(r'\\.\\d+$', '', regex=True)\n",
        "split = Sample_type_ex.index.str.split()\n",
        "first_word = split.str[0]\n",
        "second_word = split.str[1]\n",
        "third_word = split.str[2]\n",
        "fourth_word = split.str[3]\n",
        "fourth = fourth_word.str.split('.')\n",
        "Sample_type_ex['Condition'] = first_word\n",
        "Sample_type_ex['Biopsy'] = third_word + fourth_word\n",
        "print(Sample_type_ex.info)"
      ],
      "metadata": {
        "id": "W7dutCM3OU5L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pDbviBSwlNJ6",
        "7SViI7E9pYuQ",
        "MjD0boLeIrDE",
        "S7CO7zH-ABKf",
        "b_ZYozyKOU4_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}